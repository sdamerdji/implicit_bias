---
title: "Clean Data"
author: "Salim Damerdji"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(chron)
library(data.table)
```

#### Load Data

After loading the data and removing incomplete observations, to each dataframe I add a column that indicates which computer the subject took the experiment on.

```{r load data, warning=FALSE}
get_iat_tibble <- function(file_name, cp_num){
  df <- read.csv(file_name) %>%
    as_tibble() %>%
    select_if(function(x) !(all(is.na(x)) | all(x==""))) %>%
    na.omit() %>%
    mutate(cp = cp_num)
  return(df)
}

aj1 <- get_iat_tibble('../data/raw/RESULTS_aj_1.csv', 1)
aj2 <- get_iat_tibble('../data/raw/RESULTS_aj_2.csv', 1)
rb1 <- get_iat_tibble('../data/raw/RESULTS_rb_1.csv', 2)
rb2 <- get_iat_tibble('../data/raw/RESULTS_rb_2.csv', 2)
rb3 <- get_iat_tibble('../data/raw/RESULTS_rb_3.csv', 2)
sd1 <- get_iat_tibble('../data/raw/RESULTS_sd_1.csv', 3)
sd2 <- get_iat_tibble('../data/raw/RESULTS_sd_2.csv', 3)
```

#### Merge Data

```{r merge}
# Rename columns so they can be merged
sd1 <- rename_at(sd1, vars(contains('X')), funs(sub('X', 'stage', .)))
listDf = list(aj1, aj2, rb1, rb2, rb3, sd1, sd2)
for (i in seq_along(listDf)){
  setnames(listDf[[i]], colnames(sd1))
}

# Merge
merged_unbalanced <- rbind(aj1,aj2,rb1,rb2,rb3,sd1,sd2) %>%
  mutate(time = chron(times = time))
```

#### Balance the dataset

We have an imbalanced dataset since not all treatment/block combinations are equally represented in our dataset. This can be seen below:
```{r tidy_balance}
merged_unbalanced %>%
  group_by(gender, factor) %>%
  count()
```

We can balance this dataset by removing extraneous observations. I can do this by taking only 6 subjects per treatment/block combination. If a treatment/block combination has k subjects, where k>6, I remove the k-6 subjects who took the experiment **last.**

Someone else might prefer to remove observations according to some metric that would improve power. For example, they could remove the noisiest subjects. But I worry this approach would introduce bias. It's more neutral to merely removing the subjects who took the experiment last.

```{r balance}
balanced <- merged_unbalanced %>% 
  group_by(factor, gender) %>%
  top_n(n=6, wt=time) %>%
  ungroup() %>%
  arrange(time) %>%
  mutate(subject_id = 1:48)
```

#### Tidy the Data

Transform dataframe so every row is an observation (a reaction time) and every column is a variable.

```{r tidy_so_rows_are_reaction_times}
# Tidy the dataset, in the Hadley Wickham sense of 'tidy', not the KonMari sense
(tidy_balanced <- balanced %>%
  select(subject_id, cp, time, factor, gender, everything()) %>%
  gather(key = 'trial', value = 'response', 6:75))
```

#### Outliers

##### Exploration of Outliers
Greenwald et al's meta-analysis recommends IAT studies defines outliers as reaction times that last longer than 10 seconds. 

```{r outliers too_slow}
tidy_balanced %>%
  filter(grepl("stage[3,5]",trial)) %>% # only reaction times from stages 3 and 5
  group_by(subject_id) %>% # count towards the IAT score
  filter(response > 10)
```

By this metric, there are 14 outlier response times to remove. These reaction times are so slow they indicate the subject was significantly distracted, attempted to get clarification on instructions, or did something else anamolous. Outlier removal filters out this noise.

```{r num_obs}
tidy_balanced %>%
  filter(grepl("stage[3,5]",trial)) %>%
  nrow()
```
Since there are 1920 total observations, these outliers account for 0.7% of all observations.

Greenwald et al also recommends removing data for participants where more than 10% of their reaction times were under 300 milliseconds. This strategy helps address cases where participants are answering so quickly they could not *really* be reading the stimuli words. We don't have any subjects who did this:

```{r too_fast}
tidy_balanced %>%
  group_by(subject_id) %>%
  filter(response < .3) %>%
  count()
```
No subject reacted that quickly more than twice, which is far below the 10% threshold.

##### Remove Outliers
```{r remove_outliers}
no_outliers <- tidy_balanced %>%
  group_by(subject_id) %>%
  filter(response < 10)
```

#### Create Final Dataframe

Ultimately, our analysis is only of how treatment affects the IAT scores. We only care about the IAT scores's summary of the reaction times, not the reaction times themselves. So, for our analysis, we should retidy data so rows are particpants, rather than reaction times. And we'll add a feature that tells us a subject's IAT score. Our scoring metric is justified further in the write-up. In short, the score is the difference of mean response times for stage 3 & 5, divided by standard deviation of response times across both stages for that person. 

```{r calculate_means}
# Remove stages 1,2,4
df <- no_outliers %>%
  filter(grepl("stage[3,5]",trial)) %>%
  arrange(subject_id)

# Determine each subject's mean response time for
# stage 3 (male_leader) and 5 (female_leader)
(mean_response <- df %>% 
  mutate(is_stage_3 = grepl("stage3",trial)) %>%
  group_by(subject_id, cp, time, factor, gender, is_stage_3) %>%
  summarise(mean = mean(response)) %>%
  spread(key = is_stage_3, value = mean) %>%
  rename(stage3_mean = 'TRUE', stage5_mean = 'FALSE'))
```

We use the mean_response dataframe to compute IAT scores

```{r iat_score}
(iat_df <- df %>% 
  group_by(subject_id) %>%
  summarise(sd = sd(response)) %>%
  right_join(mean_response) %>%
  mutate(diff = (stage5_mean - stage3_mean)) %>%
  mutate(iat_d = diff/sd) %>%
  select(-sd, sd))
```

R's ANOVA functions are also easier to use if we add a binary feature for each treatment.
```{r}
iat_df <- iat_df %>%
  mutate(prodiversity = (factor %in% c(2,4))) %>%
  mutate(antistereotype = (factor %in% c(3,4)))
```

#### Write Out CSV

```{r output}
write.csv(iat_df, file = '../data/clean/iat_scores.csv')
```

